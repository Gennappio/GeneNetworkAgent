#!/usr/bin/env python3
"""
Gene Network Quality Agent - LangChain Production Version

A structured approach to gene network analysis with LLM integration using LangChain.
"""

import argparse
import sys
import os
from pathlib import Path
from typing import List
import logging

# LangChain imports
from langchain_openai import ChatOpenAI

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class GeneAgent:
    """Main Gene Network Quality Agent with LangChain integration"""

    def __init__(self, verbose: bool = False):
        self.verbose = verbose
        if verbose:
            logger.setLevel(logging.DEBUG)

        # OpenAI API key from environment variable
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        if not self.openai_api_key:
            logger.error("OPENAI_API_KEY environment variable not set")
            sys.exit(1)

        # Set up LangChain ChatOpenAI
        try:
            self.llm = ChatOpenAI(
                api_key=self.openai_api_key,
                model="gpt-3.5-turbo",
                temperature=0.1,
                max_tokens=2000
            )
            logger.info("LangChain ChatOpenAI initialized")
        except ImportError:
            logger.error("LangChain packages not installed. Run: pip install langchain langchain-openai")
            sys.exit(1)





    def run_default_pipeline(self, model_path: str) -> str:
        """
        Run analysis pipeline with natural language communication between agents

        Args:
            model_path: Path to .bnd network file

        Returns:
            Path to generated report file
        """
        logger.info(f"Running analysis pipeline on {model_path}")

        # Dynamically discover and order analysis agents
        available_tools_dict = self._discover_available_tools()

        # Sort tools by priority (higher priority first)
        sorted_tools = sorted(
            available_tools_dict.items(),
            key=lambda x: x[1]['definition'].get('priority', 50),
            reverse=True
        )

        agents = [
            (tool_info['display_name'], tool_info['module'])
            for _, tool_info in sorted_tools
        ]

        # Initialize with just the model path
        context = f"Analyzing gene network: {model_path}"
        analysis_results = []

        # Run each agent and collect natural language results
        for step, (agent_name, agent_module) in enumerate(agents, 1):
            logger.info(f"Step {step}: {agent_name}...")

            # Import and execute agent
            module_parts = agent_module.split('.')
            module = __import__(agent_module, fromlist=[module_parts[-1]])
            agent_result = module.execute_natural_language(context, model_path)

            # Collect the natural language evaluation
            analysis_results.append(f"## {agent_name}\n{agent_result}\n")

            # Update context for next agent
            context += f"\n\nPrevious analysis from {agent_name}:\n{agent_result}"

        # Generate final report
        logger.info("Generating final report...")
        report_path = self._generate_natural_language_report(model_path, analysis_results)

        logger.info(f"Analysis pipeline completed. Report: {report_path}")
        return report_path
        

        

        
    def _generate_natural_language_report(self, model_path: str, analysis_results: List[str]) -> str:
        """Generate natural language report from agent evaluations"""

        # Create reports directory
        reports_dir = Path("reports")
        reports_dir.mkdir(exist_ok=True)

        # Generate timestamp
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # Create natural language report
        report_content = f"""# Gene Network Analysis Report

            **Network:** {Path(model_path).name}
            **Analysis Date:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
            **Report Type:** Comprehensive Analysis Pipeline

            ## Executive Summary

            This report presents a comprehensive analysis of the gene network using multiple specialized agents. Each agent provides an independent evaluation in natural language, making the results accessible to both technical and biological researchers.

            ## Detailed Analysis Results

            {''.join(analysis_results)}

            ## Conclusion

            The analysis pipeline has completed successfully. Each agent has provided its specialized evaluation above. This natural language format allows for easy interpretation and integration of results across different analytical perspectives.

            ---
            *Generated by Gene Network Quality Agent - Natural Language Pipeline*
            """

        # Save natural language report
        report_path = reports_dir / f"analysis_report_{timestamp}.md"
        with open(report_path, 'w') as f:
            f.write(report_content)

        logger.info(f"Natural language report: {report_path}")

        return str(report_path)



    def _discover_available_tools(self) -> dict:
        """Dynamically discover all available tools from the tools directory"""
        tools = {}
        tools_dir = Path("agent/tools")

        if not tools_dir.exists():
            logger.warning(f"Tools directory not found: {tools_dir}")
            return tools

        for tool_file in tools_dir.glob("*.py"):
            if tool_file.name.startswith("__"):
                continue

            try:
                # Import the module dynamically
                module_name = f"agent.tools.{tool_file.stem}"
                module_parts = module_name.split('.')
                module = __import__(module_name, fromlist=[module_parts[-1]])

                # Check if it has TOOL_DEFINITION
                if hasattr(module, 'TOOL_DEFINITION'):
                    tool_def = module.TOOL_DEFINITION
                    if tool_def.get('enabled', True):  # Only include enabled tools
                        tools[tool_def['name']] = {
                            'definition': tool_def,
                            'module': module_name,
                            'display_name': tool_def['name'].replace('_', ' ').title()
                        }

            except Exception as e:
                logger.warning(f"Failed to load tool {tool_file}: {e}")

        return tools

    def _extract_tool_recommendations(self, response_text: str) -> list:
        """Extract tool recommendations from LLM response using dynamic tool discovery"""
        recommended_tools = []

        # Get available tools dynamically
        available_tools = self._discover_available_tools()

        response_lower = response_text.lower()

        # Check for tool mentions by name and description keywords
        for tool_name, tool_info in available_tools.items():
            tool_def = tool_info['definition']
            display_name = tool_info['display_name']

            # Check for direct tool name mentions
            if tool_name.lower() in response_lower or display_name.lower() in response_lower:
                if any(trigger in response_lower for trigger in ["should be run", "recommend", "suggest", "execute", "run"]):
                    recommended_tools.append(display_name)
                    continue

            # Check for description-based keywords
            description = tool_def.get('description', '').lower()
            description_words = description.split()

            # If multiple description words are mentioned, consider it a recommendation
            matches = sum(1 for word in description_words if len(word) > 3 and word in response_lower)
            if matches >= 2 and any(trigger in response_lower for trigger in ["should be run", "recommend", "suggest", "execute", "run"]):
                recommended_tools.append(display_name)

        return list(set(recommended_tools))  # Remove duplicates

    def _execute_recommended_tools(self, model_path: str, recommended_tools: list) -> str:
        """Execute recommended tools and return results"""
        if not recommended_tools:
            return ""

        logger.info(f"Executing recommended tools: {', '.join(recommended_tools)}")

        # Get available tools dynamically
        available_tools_dict = self._discover_available_tools()

        # Create mapping from display names to modules
        tool_modules = {}
        for tool_name, tool_info in available_tools_dict.items():
            display_name = tool_info['display_name']
            tool_modules[display_name] = tool_info['module']

        results = []
        context = f"Analyzing gene network: {model_path}"

        for tool_name in recommended_tools:
            if tool_name in tool_modules:
                try:
                    module_name = tool_modules[tool_name]
                    module_parts = module_name.split('.')
                    module = __import__(module_name, fromlist=[module_parts[-1]])
                    result = module.execute_natural_language(context, model_path)
                    results.append(f"## {tool_name}\n{result}\n")
                    context += f"\n\nPrevious analysis from {tool_name}:\n{result}"
                except Exception as e:
                    logger.error(f"Failed to execute {tool_name}: {e}")
                    results.append(f"## {tool_name}\nFailed to execute: {e}\n")
            else:
                logger.warning(f"Tool not found: {tool_name}. Available tools: {list(tool_modules.keys())}")

        return "\n".join(results)

    def _extract_model_path_from_report(self, report_path: str) -> str:
        """Extract the original model path from the report file"""
        try:
            with open(report_path, 'r') as f:
                content = f.read()

            # Look for the network name in the report
            import re
            match = re.search(r'\*\*Network:\*\* (.+?)\.bnd', content)
            if match:
                network_name = match.group(1)
                # Try to find the corresponding .bnd file
                possible_paths = [
                    f"models/{network_name}.bnd",
                    f"{network_name}.bnd",
                    f"../models/{network_name}.bnd"
                ]

                for path in possible_paths:
                    if os.path.exists(path):
                        return path

            return None
        except Exception as e:
            logger.error(f"Failed to extract model path from report: {e}")
            return None







    def _save_biologist_summary(self, report_path: str, summary: str, focus: str) -> str:
        """Save biologist-friendly summary"""
        summary_path = report_path.replace('.md', f'_biologist_summary_{focus.replace(" ", "_")}.md')

        with open(summary_path, 'w') as f:
            f.write(f"# Gene Network Analysis Summary\n\n")
            f.write(f"**Focus:** {focus}\n\n")
            f.write(f"**Source Report:** {report_path}\n\n")
            f.write(summary)

        return summary_path


def main():
    """Main CLI entry point"""
    parser = argparse.ArgumentParser(
        description="Gene Network Quality Agent - Structured Analysis with LLM Integration",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
            Examples:
            # Run default analysis pipeline
            python gene_agent.py network.bnd --default-pipeline

            # Refine analysis with LLM review
            python gene_agent.py --refine report.yaml

            # Ask specific question about analysis
            python gene_agent.py --refine report.yaml --ask "What are the key regulatory hubs?"

            # Create biologist summary
            python gene_agent.py --refine report.yaml --summarize "therapeutic targets"
                    """
    )

    # Positional argument for network file (optional)
    parser.add_argument('network_file', nargs='?', help='Path to .bnd network file')

    # Mode flags
    parser.add_argument('--default-pipeline', action='store_true',
                       help='Run standard analysis pipeline and generate structured report')
    parser.add_argument('--refine', metavar='REPORT_FILE',
                       help='Refine analysis using LLM review of existing report')
    parser.add_argument('--ask', metavar='QUESTION',
                       help='Ask specific question about the analysis (use with --refine)')
    parser.add_argument('--summarize', metavar='FOCUS',
                       help='Create biologist-friendly summary with given focus (use with --refine)')

    # Options
    parser.add_argument('--model', default='gpt-3.5-turbo',
                       help='AI model to use (default: gpt-3.5-turbo)')
    parser.add_argument('--verbose', action='store_true',
                       help='Enable verbose logging')

    args = parser.parse_args()

    # Show help if no arguments
    if len(sys.argv) == 1:
        parser.print_help()
        return

    # Initialize agent
    agent = GeneAgent(verbose=args.verbose)

    try:
        if args.default_pipeline:
            if not args.network_file:
                print("Error: Network file required for --default-pipeline")
                sys.exit(1)
            report_path = agent.run_default_pipeline(args.network_file)
            print(f"Analysis complete. Report: {report_path}")

        elif args.refine:
            # Load the report content
            with open(args.refine, 'r') as f:
                report_content = f.read()

            if args.ask:
                # Use question agent directly
                from reasoning_agents.question_agent import execute_natural_language
                answer, recommended_tools = execute_natural_language(report_content, args.ask)
                print(answer)

                # Execute recommended tools if any
                if recommended_tools:
                    model_path = agent._extract_model_path_from_report(args.refine)
                    if model_path:
                        additional_analysis = agent._execute_recommended_tools(model_path, recommended_tools)
                        if additional_analysis:
                            print(f"\n## Additional Analysis Results\n{additional_analysis}")

            elif args.summarize:
                # Use summary agent directly
                from reasoning_agents.summary_agent import execute_natural_language
                summary = execute_natural_language(report_content, args.summarize)

                # Save the summary
                summary_path = args.refine.replace('.md', f'_biologist_summary_{args.summarize.replace(" ", "_")}.md')
                with open(summary_path, 'w') as f:
                    f.write(f"# Gene Network Analysis Summary\n\n")
                    f.write(f"**Focus:** {args.summarize}\n\n")
                    f.write(f"**Source Report:** {args.refine}\n\n")
                    f.write(summary)
                print(f"Summary created: {summary_path}")

            else:
                # Use refinement agent directly
                from reasoning_agents.refinement_agent import execute_natural_language
                suggestions, recommended_tools = execute_natural_language(report_content)
                print(suggestions)

                # Execute recommended tools if any
                if recommended_tools:
                    model_path = agent._extract_model_path_from_report(args.refine)
                    if model_path:
                        additional_analysis = agent._execute_recommended_tools(model_path, recommended_tools)
                        if additional_analysis:
                            print(f"\n## Additional Analysis Results\n{additional_analysis}")

        else:
            print("Error: Please specify a mode (--default-pipeline or --refine)")
            parser.print_help()
            sys.exit(1)

    except Exception as e:
        logger.error(f"Error: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
